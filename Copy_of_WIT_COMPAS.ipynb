{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiNxsd4_q9wq"
   },
   "source": [
    "### What-If Tool on COMPAS\n",
    "\n",
    "Copyright 2019 Google LLC.\n",
    "SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "This notebook shows use of the [What-If Tool](https://pair-code.github.io/what-if-tool) on the COMPAS dataset.\n",
    "\n",
    "\n",
    "For ML fairness background on COMPAS see:\n",
    "- https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\n",
    "- https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm\n",
    "- http://www.crj.org/assets/2017/07/9_Machine_bias_rejoinder.pdf\n",
    "\n",
    "The dataset is from the [COMPAS kaggle page](https://www.kaggle.com/danofer/compass).\n",
    "\n",
    "This notebook trains a linear classifier on the on the COMPAS dataset to mimic the behavior of the the COMPAS recidivism classifier. We can then analyze our COMPAS proxy model for fairness using the What-If Tool.\n",
    "\n",
    "The specific binary classification task for this model is to determine if a person belongs in the \"Low\" risk class according to COMPAS (negative class), or the \"Medium\" or \"High\" risk class (positive class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqB2tjOMETmr",
    "outputId": "f321604b-5e17-4076-cb94-e9ce0c32bf2b"
   },
   "outputs": [],
   "source": [
    "#@title Install the What-If Tool widget if running in colab {display-mode: \"form\"}\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  import os\n",
    "  !pip install --upgrade witwidget\n",
    "  os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "  import google.protobuf\n",
    "  print(f\"Protobuf version: {google.protobuf.__version__}\")\n",
    "  print(f\"Using PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION={os.environ.get('PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION', 'cpp')}\")\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jlwjF-Nnmoww"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yufan Wang\\.conda\\envs\\compas_wit1\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#@title Define helper functions {display-mode: \"form\"}\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "\n",
    "# Creates a tf feature spec from the dataframe and columns specified.\n",
    "def create_feature_spec(df, columns=None):\n",
    "    feature_spec = {}\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for f in columns:\n",
    "        if df[f].dtype is np.dtype(np.int64):\n",
    "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.int64)\n",
    "        elif df[f].dtype is np.dtype(np.float64):\n",
    "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.float32)\n",
    "        else:\n",
    "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.string)\n",
    "    return feature_spec\n",
    "\n",
    "# Creates Keras preprocessing layers for features (replaces deprecated feature columns)\n",
    "# Returns a dictionary mapping feature names to preprocessing layers\n",
    "def create_preprocessing_layers(columns, feature_spec, df):\n",
    "    preprocessing_layers = {}\n",
    "    for col in columns:\n",
    "        if feature_spec[col].dtype == tf.string:\n",
    "            # Categorical string feature - use StringLookup with one-hot encoding\n",
    "            vocab = sorted(list(df[col].dropna().unique()))\n",
    "            preprocessing_layers[col] = tf.keras.layers.StringLookup(\n",
    "                vocabulary=vocab, output_mode='one_hot', name=f'{col}_lookup')\n",
    "        elif feature_spec[col].dtype == tf.int64:\n",
    "            # Integer feature - convert to float and pass through\n",
    "            preprocessing_layers[col] = tf.keras.layers.Lambda(\n",
    "                lambda x: tf.cast(x, tf.float32), name=f'{col}_cast')\n",
    "        else:\n",
    "            # Float feature - pass through (or normalize if desired)\n",
    "            preprocessing_layers[col] = tf.keras.layers.Lambda(\n",
    "                lambda x: x, name=f'{col}_pass')\n",
    "    return preprocessing_layers\n",
    "\n",
    "# An input function for providing input to a model from tf.Examples\n",
    "# Updated for TensorFlow 2.16+ (no estimator API)\n",
    "def tfexamples_input_fn(examples, feature_spec, label, mode='eval',\n",
    "                       num_epochs=None,\n",
    "                       batch_size=64):\n",
    "    def ex_generator():\n",
    "        for i in range(len(examples)):\n",
    "            yield examples[i].SerializeToString()\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "      ex_generator, tf.dtypes.string, tf.TensorShape([]))\n",
    "    if mode == 'train':\n",
    "        dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(lambda tf_example: parse_tf_example(tf_example, label, feature_spec))\n",
    "    if num_epochs:\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "    return dataset\n",
    "\n",
    "# Parses Tf.Example protos into features for the input function.\n",
    "def parse_tf_example(example_proto, label, feature_spec):\n",
    "    parsed_features = tf.io.parse_example(serialized=example_proto, features=feature_spec)\n",
    "    target = parsed_features.pop(label)\n",
    "    return parsed_features, target\n",
    "\n",
    "# Converts a dataframe into a list of tf.Example protos.\n",
    "def df_to_examples(df, columns=None):\n",
    "    examples = []\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for index, row in df.iterrows():\n",
    "        example = tf.train.Example()\n",
    "        for col in columns:\n",
    "            value = row[col]\n",
    "\n",
    "            # Skip NaN values\n",
    "            if pd.isna(value):\n",
    "                continue\n",
    "\n",
    "            # Check actual value type, not just column dtype\n",
    "            if isinstance(value, (int, np.integer)):\n",
    "                example.features.feature[col].int64_list.value.append(int(value))\n",
    "            elif isinstance(value, (float, np.floating)):\n",
    "                example.features.feature[col].float_list.value.append(float(value))\n",
    "            else:\n",
    "                # Everything else becomes a string\n",
    "                example.features.feature[col].bytes_list.value.append(str(value).encode('utf-8'))\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "\n",
    "# # Converts a dataframe into a list of tf.Example protos.\n",
    "# def df_to_examples(df, columns=None):\n",
    "#     examples = []\n",
    "#     if columns == None:\n",
    "#         columns = df.columns.values.tolist()\n",
    "#     for index, row in df.iterrows():\n",
    "#         example = tf.train.Example()\n",
    "#         for col in columns:\n",
    "#             if df[col].dtype is np.dtype(np.int64):\n",
    "#                 example.features.feature[col].int64_list.value.append(int(row[col]))\n",
    "#             elif df[col].dtype is np.dtype(np.float64):\n",
    "#                 example.features.feature[col].float_list.value.append(row[col])\n",
    "#             elif row[col] == row[col]:\n",
    "#                 example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "#         examples.append(example)\n",
    "#     return examples\n",
    "\n",
    "# Converts a dataframe column into a column of 0's and 1's based on the provided test.\n",
    "# Used to force label columns to be numeric for binary classification using a TF estimator.\n",
    "def make_label_column_numeric(df, label_column, test):\n",
    "  df[label_column] = np.where(test(df[label_column]), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CcdzxifPs_1E",
    "outputId": "65ecffef-f4dc-4f76-d9db-dfd52b6dac07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(hasattr(tf, 'estimator'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "nu398ARdeuxe",
    "outputId": "987a9f8b-c41a-4057-d76c-40871ad5c3fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>...</th>\n",
       "      <th>vr_charge_desc</th>\n",
       "      <th>type_of_assessment</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>score_text</th>\n",
       "      <th>screening_date</th>\n",
       "      <th>v_type_of_assessment</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>Male</td>\n",
       "      <td>18/04/1947</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>14/08/2013</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>Male</td>\n",
       "      <td>18/04/1947</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>14/08/2013</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>michael ryan</td>\n",
       "      <td>michael</td>\n",
       "      <td>ryan</td>\n",
       "      <td>Male</td>\n",
       "      <td>06/02/1985</td>\n",
       "      <td>31</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>31/12/2014</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>Male</td>\n",
       "      <td>22/01/1982</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>27/01/2013</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>Male</td>\n",
       "      <td>14/05/1991</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>14/04/2013</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>alexsandra beauchamps</td>\n",
       "      <td>alexsandra</td>\n",
       "      <td>beauchamps</td>\n",
       "      <td>Female</td>\n",
       "      <td>21/12/1984</td>\n",
       "      <td>31</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>29/12/2014</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18312</th>\n",
       "      <td>NaN</td>\n",
       "      <td>winston gregory</td>\n",
       "      <td>winston</td>\n",
       "      <td>gregory</td>\n",
       "      <td>Male</td>\n",
       "      <td>01/10/1958</td>\n",
       "      <td>57</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>14/01/2014</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18313</th>\n",
       "      <td>NaN</td>\n",
       "      <td>farrah jean</td>\n",
       "      <td>farrah</td>\n",
       "      <td>jean</td>\n",
       "      <td>Female</td>\n",
       "      <td>17/11/1982</td>\n",
       "      <td>33</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>09/03/2014</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18314</th>\n",
       "      <td>NaN</td>\n",
       "      <td>florencia sanmartin</td>\n",
       "      <td>florencia</td>\n",
       "      <td>sanmartin</td>\n",
       "      <td>Female</td>\n",
       "      <td>18/12/1992</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>30/06/2014</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18315</th>\n",
       "      <td>NaN</td>\n",
       "      <td>florencia sanmartin</td>\n",
       "      <td>florencia</td>\n",
       "      <td>sanmartin</td>\n",
       "      <td>Female</td>\n",
       "      <td>18/12/1992</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>30/06/2014</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18316 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                   name       first        last     sex         dob  \\\n",
       "0      1.0       miguel hernandez      miguel   hernandez    Male  18/04/1947   \n",
       "1      2.0       miguel hernandez      miguel   hernandez    Male  18/04/1947   \n",
       "2      3.0           michael ryan     michael        ryan    Male  06/02/1985   \n",
       "3      4.0            kevon dixon       kevon       dixon    Male  22/01/1982   \n",
       "4      5.0               ed philo          ed       philo    Male  14/05/1991   \n",
       "...    ...                    ...         ...         ...     ...         ...   \n",
       "18311  NaN  alexsandra beauchamps  alexsandra  beauchamps  Female  21/12/1984   \n",
       "18312  NaN        winston gregory     winston     gregory    Male  01/10/1958   \n",
       "18313  NaN            farrah jean      farrah        jean  Female  17/11/1982   \n",
       "18314  NaN    florencia sanmartin   florencia   sanmartin  Female  18/12/1992   \n",
       "18315  NaN    florencia sanmartin   florencia   sanmartin  Female  18/12/1992   \n",
       "\n",
       "       age          age_cat              race  juv_fel_count  ...  \\\n",
       "0       69  Greater than 45             Other              0  ...   \n",
       "1       69  Greater than 45             Other              0  ...   \n",
       "2       31          25 - 45         Caucasian              0  ...   \n",
       "3       34          25 - 45  African-American              0  ...   \n",
       "4       24     Less than 25  African-American              0  ...   \n",
       "...    ...              ...               ...            ...  ...   \n",
       "18311   31          25 - 45  African-American              0  ...   \n",
       "18312   57  Greater than 45             Other              0  ...   \n",
       "18313   33          25 - 45  African-American              0  ...   \n",
       "18314   23     Less than 25          Hispanic              0  ...   \n",
       "18315   23     Less than 25          Hispanic              0  ...   \n",
       "\n",
       "                    vr_charge_desc  type_of_assessment  decile_score.1  \\\n",
       "0                              NaN  Risk of Recidivism               1   \n",
       "1                              NaN  Risk of Recidivism               1   \n",
       "2                              NaN  Risk of Recidivism               5   \n",
       "3      Felony Battery (Dom Strang)  Risk of Recidivism               3   \n",
       "4                              NaN  Risk of Recidivism               4   \n",
       "...                            ...                 ...             ...   \n",
       "18311                          NaN  Risk of Recidivism               6   \n",
       "18312                          NaN  Risk of Recidivism               1   \n",
       "18313                          NaN  Risk of Recidivism               2   \n",
       "18314                          NaN  Risk of Recidivism               4   \n",
       "18315                          NaN  Risk of Recidivism               4   \n",
       "\n",
       "       score_text  screening_date v_type_of_assessment v_decile_score  \\\n",
       "0             Low      14/08/2013     Risk of Violence              1   \n",
       "1             Low      14/08/2013     Risk of Violence              1   \n",
       "2          Medium      31/12/2014     Risk of Violence              2   \n",
       "3             Low      27/01/2013     Risk of Violence              1   \n",
       "4             Low      14/04/2013     Risk of Violence              3   \n",
       "...           ...             ...                  ...            ...   \n",
       "18311      Medium      29/12/2014     Risk of Violence              4   \n",
       "18312         Low      14/01/2014     Risk of Violence              1   \n",
       "18313         Low      09/03/2014     Risk of Violence              2   \n",
       "18314         Low      30/06/2014     Risk of Violence              4   \n",
       "18315         Low      30/06/2014     Risk of Violence              4   \n",
       "\n",
       "       v_score_text priors_count.1 event  \n",
       "0               Low              0     0  \n",
       "1               Low              0     0  \n",
       "2               Low              0     0  \n",
       "3               Low              0     1  \n",
       "4               Low              4     0  \n",
       "...             ...            ...   ...  \n",
       "18311           Low              5     0  \n",
       "18312           Low              0     0  \n",
       "18313           Low              3     0  \n",
       "18314           Low              2     0  \n",
       "18315           Low              2     0  \n",
       "\n",
       "[18316 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Read training dataset from CSV {display-mode: \"form\"}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://storage.googleapis.com/what-if-tool-resources/computefest2019/cox-violent-parsed_filt.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67DYIFxoevt2",
    "outputId": "127d62a3-bf9d-48e7-edad-78065e3d6680"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex',\n",
       " 'age',\n",
       " 'race',\n",
       " 'priors_count',\n",
       " 'juv_fel_count',\n",
       " 'juv_misd_count',\n",
       " 'juv_other_count',\n",
       " 'recidivism_within_2_years',\n",
       " 'COMPASS_determination']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Specify input columns and column to predict {display-mode: \"form\"}\n",
    "import numpy as np\n",
    "\n",
    "# Filter out entries with no indication of recidivism or no compass score\n",
    "df = df[df['is_recid'] != -1]\n",
    "df = df[df['decile_score'] != -1]\n",
    "\n",
    "# Rename recidivism column\n",
    "df['recidivism_within_2_years'] = df['is_recid']\n",
    "\n",
    "# Make the COMPASS label column numeric (0 and 1), for use in our model\n",
    "df['COMPASS_determination'] = np.where(df['score_text'] == 'Low', 0, 1)\n",
    "\n",
    "# Set column to predict\n",
    "label_column = 'COMPASS_determination'\n",
    "\n",
    "# Get list of all columns from the dataset we will use for model input or output.\n",
    "input_features = ['sex', 'age', 'race', 'priors_count', 'juv_fel_count', 'juv_misd_count', 'juv_other_count']\n",
    "features_and_labels = input_features + [label_column]\n",
    "\n",
    "features_for_file = input_features + ['recidivism_within_2_years', 'COMPASS_determination']\n",
    "features_for_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BV4f_4_Lex22"
   },
   "outputs": [],
   "source": [
    "#@title Convert dataset to tf.Example protos {display-mode: \"form\"}\n",
    "\n",
    "examples = df_to_examples(df, features_for_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyLr-_0de1Ii",
    "outputId": "c35ae323-c279-4f96-9c2b-b8b99eed446b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "273/273 [==============================] - 1s 1ms/step - loss: 5.7650 - accuracy: 0.4658\n",
      "Epoch 2/7\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 1.2809 - accuracy: 0.6077\n",
      "Epoch 3/7\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 0.5481 - accuracy: 0.7368\n",
      "Epoch 4/7\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7387\n",
      "Epoch 5/7\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.7441\n",
      "Epoch 6/7\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.7472\n",
      "Epoch 7/7\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 0.5159 - accuracy: 0.7476\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7368\n",
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "#@title Create and train the classifier {display-mode: \"form\"}\n",
    "\n",
    "num_steps = 2000  #@param {type: \"number\"}\n",
    "\n",
    "# Create a feature spec for the classifier\n",
    "feature_spec = create_feature_spec(df, features_and_labels)\n",
    "\n",
    "# Create preprocessing layers (replaces deprecated feature columns)\n",
    "preprocessing_layers = create_preprocessing_layers(input_features, feature_spec, df)\n",
    "\n",
    "# Build Keras model using modern preprocessing layers (compatible with TensorFlow 2.16+)\n",
    "# Create input layers\n",
    "inputs = {}\n",
    "for col in input_features:\n",
    "    if feature_spec[col].dtype == tf.string:\n",
    "        inputs[col] = tf.keras.Input(shape=(), name=col, dtype=tf.string)\n",
    "    elif feature_spec[col].dtype == tf.int64:\n",
    "        inputs[col] = tf.keras.Input(shape=(), name=col, dtype=tf.int64)\n",
    "    else:\n",
    "        inputs[col] = tf.keras.Input(shape=(), name=col, dtype=tf.float32)\n",
    "\n",
    "# Apply preprocessing layers and ensure consistent 2D shapes\n",
    "preprocessed_features = []\n",
    "for col in input_features:\n",
    "    preprocessed = preprocessing_layers[col](inputs[col])\n",
    "\n",
    "    shape_len = len(preprocessed.shape)\n",
    "    if shape_len == 1:\n",
    "        preprocessed = tf.keras.layers.Reshape((1,), name=f'{col}_reshape')(preprocessed)\n",
    "    elif shape_len > 2:\n",
    "        preprocessed = tf.keras.layers.Flatten(name=f'{col}_flatten')(preprocessed)\n",
    "\n",
    "    preprocessed_features.append(preprocessed)\n",
    "\n",
    "feature_layer = tf.keras.layers.Concatenate(axis=-1, name='feature_concat')(preprocessed_features)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid', name='predictions')(feature_layer)\n",
    "classifier = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "classifier.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ========= ðŸ”´ ä»Žè¿™é‡Œå¼€å§‹æ˜¯æ–°åŠ çš„éƒ¨åˆ†ï¼Œæ›¿æ¢æŽ‰åŽŸæ¥çš„ tfexamples_input_fn =========\n",
    "\n",
    "# æŠŠæ ‡ç­¾åˆ—å˜æˆ float32\n",
    "labels = df[label_column].astype('float32').values\n",
    "\n",
    "# æž„é€ ç‰¹å¾å­—å…¸ï¼šä¿æŒåˆ—åä¸å˜ï¼Œè®© Keras è¾“å…¥å’Œå‰é¢å®šä¹‰çš„ inputs å¯¹å¾—ä¸Š\n",
    "features_dict = {}\n",
    "for col in input_features:\n",
    "    # å­—ç¬¦ä¸²ç‰¹å¾ä¿æŒä¸ºå­—ç¬¦ä¸²æ•°ç»„ï¼Œæ•°å€¼ç‰¹å¾ä¿æŒä¸ºæ•°å€¼\n",
    "    if df[col].dtype == 'object' or df[col].dtype.name.startswith('string'):\n",
    "        features_dict[col] = df[col].astype(str).values\n",
    "    else:\n",
    "        features_dict[col] = df[col].values\n",
    "\n",
    "# ç”¨ from_tensor_slices æž„é€  tf.data.Dataset\n",
    "batch_size = 64\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features_dict, labels))\n",
    "dataset = dataset.shuffle(buffer_size=len(df), reshuffle_each_iteration=True)\n",
    "train_dataset = dataset.batch(batch_size).repeat()\n",
    "\n",
    "# æ ¹æ® num_steps è®¡ç®—éœ€è¦çš„ epoch å’Œ steps_per_epoch\n",
    "dataset_size = len(df)\n",
    "steps_per_epoch = max(1, dataset_size // batch_size)\n",
    "epochs = max(1, num_steps // steps_per_epoch)\n",
    "remaining_steps = num_steps % steps_per_epoch\n",
    "\n",
    "# è®­ç»ƒæ¨¡åž‹\n",
    "if epochs > 0:\n",
    "    classifier.fit(train_dataset,\n",
    "                   epochs=epochs,\n",
    "                   steps_per_epoch=steps_per_epoch,\n",
    "                   verbose=1)\n",
    "\n",
    "if remaining_steps > 0:\n",
    "    classifier.fit(train_dataset,\n",
    "                   epochs=1,\n",
    "                   steps_per_epoch=remaining_steps,\n",
    "                   verbose=1)\n",
    "\n",
    "print(\"Model training completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZ-rK11X5arK"
   },
   "source": [
    "### What-If Tool analysis\n",
    "\n",
    "We can see the same unfairness that ProPublica found in their analysis by:\n",
    "1. Going the the \"Performance + Fairness\" tab\n",
    "2. Setting \"Ground Truth Feature\" to \"recidivism_within_2_years\"\n",
    "3. In \"Slice by\" dropdown menu, select \"race\"\n",
    "4. Look at the confusion matrices of the \"African-American\" and \"Causasian\" slices.\n",
    "  - They have very similar accuracy (TP+TN)/Total\n",
    "  - But, the FP rate is MUCH higher for African Americans and the FN rate is MUCH higher for caucasians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "resources": {
      "http://localhost:8080/data/plugins_listing": {
       "data": "",
       "headers": [
        [
         "content-length",
         "0"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/font-roboto/RxZJdnzeo3R5zSexge8UUZBw1xU1rKptJj_0jans920.woff2": {
       "data": "",
       "headers": [
        [
         "content-length",
         "0"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/font-roboto/d-6IYplOFocCacKzxwXSOJBw1xU1rKptJj_0jans920.woff2": {
       "data": "",
       "headers": [
        [
         "content-length",
         "0"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/font-roboto/oMMgfZMQthOryQo9n22dcuvvDin1pK8aKteLpeZ5c0A.woff2": {
       "data": "",
       "headers": [
        [
         "content-length",
         "0"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "id": "NUQVro76e38Q",
    "outputId": "bd232eb3-35e3-4cfc-84ac-5ff98bcd857a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d386201d4dee4056baee6cdf8c6110de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WitWidget(config={'model_type': 'classification', 'label_vocab': [], 'are_sequence_examples': False, 'inferencâ€¦"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Invoke What-If Tool for test data and the trained models {display-mode: \"form\"}\n",
    "\n",
    "import os\n",
    "\n",
    "# Ensure protobuf compatibility\n",
    "if 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION' not in os.environ:\n",
    "    os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "num_datapoints = 10000  #@param {type: \"number\"}\n",
    "tool_height_in_px = 1000  #@param {type: \"number\"}\n",
    "\n",
    "from witwidget.notebook.visualization import WitConfigBuilder\n",
    "from witwidget.notebook.visualization import WitWidget\n",
    "\n",
    "# Create a custom prediction function for Keras model\n",
    "# WIT widget expects a function that takes tf.Example protos and returns predictions\n",
    "def predict_fn(examples_list):\n",
    "    \"\"\"\n",
    "    Prediction function for WIT widget.\n",
    "    Takes a list of tf.Example protos and returns predictions.\n",
    "    \"\"\"\n",
    "    # Parse examples into feature dictionaries\n",
    "    parsed_examples = []\n",
    "    for example_proto in examples_list:\n",
    "        # Parse the tf.Example\n",
    "        parsed = tf.io.parse_example(\n",
    "            serialized=[example_proto.SerializeToString()],\n",
    "            features=feature_spec\n",
    "        )\n",
    "        # Extract only input features (remove label if present)\n",
    "        features_dict = {col: parsed[col] for col in input_features if col in parsed}\n",
    "        parsed_examples.append(features_dict)\n",
    "\n",
    "    # Convert to batched format for model prediction\n",
    "    # Model expects dict of {feature_name: tensor} where tensors have batch dimension\n",
    "    batch_features = {}\n",
    "    for col in input_features:\n",
    "        batch_features[col] = tf.stack([ex[col] for ex in parsed_examples])\n",
    "\n",
    "    # Get predictions from model\n",
    "    predictions = classifier(batch_features, training=False)\n",
    "\n",
    "    # Return predictions in format expected by WIT\n",
    "    # For binary classification, return probabilities for both classes\n",
    "    # Shape: (batch_size, 2) where [prob_class_0, prob_class_1]\n",
    "    prob_class_1 = predictions.numpy().flatten()\n",
    "    prob_class_0 = 1 - prob_class_1\n",
    "    return tf.stack([prob_class_0, prob_class_1], axis=1).numpy()\n",
    "\n",
    "# Setup the tool with the test examples and the trained classifier\n",
    "# Updated for Keras models (TensorFlow 2.16+) using custom prediction function\n",
    "config_builder = WitConfigBuilder(examples[0:num_datapoints]).set_custom_predict_fn(\n",
    "    predict_fn)\n",
    "WitWidget(config_builder, height=tool_height_in_px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOVamCz1LsTd"
   },
   "source": [
    "#### Exploration ideas\n",
    "\n",
    "- Organize datapoints by \"inference score\" (can do this through binning or use of scatter plot) to see points ordered by how likely they were determined to re-offend.\n",
    "  - Select a point near the boundary line (where red points turn to blue points)\n",
    "  - Find the nearest counterfactual to see a similar person with a different decision. What is different?\n",
    "  - Look at the partial dependence plots for the selected person. What changes in what features would change the decision on this person?\n",
    "- In \"Performance and Fairness\" tab, slice the dataset by different features (such as race or sex)\n",
    "  - Look at the confusion matrices for each slice - How does performance compare in those slices? What from the training data may have caused the difference in performance between the slices? What root causes could exist?\n",
    "  - Use the threshold optimization buttons to optimize positive classification thresholds for each slice based on any of the possible fairness constraints - How different do the thresholds have to be to achieve that constraint? How varied are the thresholds depending on the fairness constraint chosen?\n",
    "\n",
    "- In the \"Performance + Fairness\" tab, change the cost ratio so that you can optimize the threshold based off of a non-symmetric cost of false positives vs false negatives. Then click the \"optimize threshold\" button and see the effect on the confusion matrix.\n",
    "  - Slice the dataset by a feature, such as sex or race. How has the new cost ratio affected the disparity in performance between slices? Click the different threshold optimization buttons to see how the changed cost ratio affects the disparity given different fairness constraints.\n",
    "\n",
    "- Try adding/removing features from the set of input features that the model uses during training. The model trained by this notebook only uses 7 of the columns from the dataset, as defined in the \"Specify input columns and column to predict\" cell in this notebook. How does your new set of input features affect the model performance (overall and across slices).\n",
    "\n",
    "- If you set the ground truth feature to \"COMPAS_determination\" in the \"Performance + Fairness\" tab, you will see the confusion matrix and ROC curve of how good our model is at being a proxy for the COMPAS model itself (as opposed to how good our model is at predicting recidivism).\n",
    "  - How well is our model doing at its task? What types of errors does it have?\n",
    "  - Try improving the performance of the model. Options include adding more input features, changing the model architecture, and training for more steps.\n",
    "  - After you've improved our proxy COMPAS model, what (if any) change in unfairness do you see when evaluating against \"recidivism_after_2_years\"?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (compas_wit1)",
   "language": "python",
   "name": "compas_wit1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
